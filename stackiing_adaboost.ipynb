{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "606b2bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['date', 'actual_lstm', 'predicted_lstm', 'predicted_prob_lstm', 'prediction_date_lstm', 'model_version_lstm', 'actual_gru', 'predicted_gru', 'predicted_prob_gru', 'prediction_date_gru', 'model_version_gru', 'actual', 'predicted_prob_gbt', 'predicted', 's', 'o', 'h', 'l', 'c_x', 'v', 'psar_x', 'PosDI_x', 'NegDI_x', 'ADX_x', 'accumulated_sentiment_x', 'forecast_price', 'actual_label', 'predicted_label', 'c_y', 'psar_y', 'PosDI_y', 'NegDI_y', 'ADX_y', 'accumulated_sentiment_y']\n",
      "Accuracy: 0.5956\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.58      0.62        77\n",
      "           1       0.53      0.61      0.57        59\n",
      "\n",
      "    accuracy                           0.60       136\n",
      "   macro avg       0.60      0.60      0.59       136\n",
      "weighted avg       0.60      0.60      0.60       136\n",
      "\n",
      "\n",
      "Predictions saved to: model_predictions_stacked_adaboost.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 1. LOAD AND PREPARE DATA\n",
    "# --------------------------------------------------\n",
    "\n",
    "# Load data\n",
    "lstm_df = pd.read_csv('model_predictions-lstm-aws.csv')\n",
    "gru_df = pd.read_csv('model_predictions-gru-aws.csv')\n",
    "gbt_df = pd.read_csv('gbt_predictions15days.csv')\n",
    "arima_df = pd.read_csv('sarima_predictions.csv')\n",
    "feat_df = pd.read_csv('stock_with_sentiment-aggregated.csv')\n",
    "\n",
    "\n",
    "gru_df['date'] = pd.to_datetime(gru_df['date'])\n",
    "gbt_df['date'] = pd.to_datetime(gbt_df['date'])\n",
    "for df in [lstm_df, gru_df, gbt_df, arima_df, feat_df]:\n",
    "    df['date'] = df['date'].astype(str)\n",
    "\n",
    "# Select features from features dataframe\n",
    "feat_df = feat_df[['date', 'c', 'psar', 'PosDI', 'NegDI', 'ADX', 'accumulated_sentiment']]\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 2. MERGE ALL DATA\n",
    "# --------------------------------------------------\n",
    "\n",
    "# Merge all model predictions\n",
    "merged = pd.merge(lstm_df, gru_df, on='date', suffixes=('_lstm', '_gru'), how='inner')\n",
    "merged = pd.merge(merged, gbt_df, on='date', how='left')\n",
    "merged = pd.merge(merged, arima_df, on='date', how='left')\n",
    "merged = pd.merge(merged, feat_df, on='date', how='left')\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 3. CREATE FEATURES DATAFRAME\n",
    "# --------------------------------------------------\n",
    "\n",
    "# Create clean features dataframe\n",
    "features_df = pd.DataFrame()\n",
    "features_df['date'] = merged['date']\n",
    "\n",
    "# Target variable\n",
    "features_df['actual'] = merged['actual_lstm']\n",
    "\n",
    "# Model probabilities\n",
    "features_df['lstm_prob'] = merged['predicted_prob_lstm']\n",
    "features_df['gru_prob'] = merged['predicted_prob_gru']\n",
    "features_df['gbt_prob'] = merged['predicted_prob_gbt']\n",
    "\n",
    "merged.columns = merged.columns.str.strip()\n",
    "print(merged.columns.tolist())\n",
    "\n",
    "\n",
    "# ARIMA features\n",
    "features_df['arima_direction'] = merged['predicted_label'].astype(int)\n",
    "features_df['arima_return'] = (merged['forecast_price'] - merged['c_y']) / merged['c_y']\n",
    "\n",
    "# Technical indicators\n",
    "features_df['close_price'] = merged['c_y']\n",
    "features_df['psar'] = merged['psar_y']\n",
    "features_df['PosDI'] = merged['PosDI_y']\n",
    "features_df['NegDI'] = merged['NegDI_y']\n",
    "features_df['ADX'] = merged['ADX_y']\n",
    "features_df['accumulated_sentiment'] = merged['accumulated_sentiment_y']\n",
    "\n",
    "# Drop any rows with missing values\n",
    "features_df = features_df.dropna()\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 4. PREPARE FEATURES AND TARGET\n",
    "# --------------------------------------------------\n",
    "\n",
    "feature_cols = ['lstm_prob', 'gru_prob', 'gbt_prob', 'arima_direction', \n",
    "                'arima_return', 'close_price', 'psar', 'PosDI', 'NegDI', \n",
    "                'ADX', 'accumulated_sentiment']\n",
    "\n",
    "X = features_df[feature_cols].values\n",
    "y = features_df['actual'].values\n",
    "\n",
    "# Time-based split\n",
    "split = int(0.8 * len(X))\n",
    "X_train, X_test = X[:split], X[split:]\n",
    "y_train, y_test = y[:split], y[split:]\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 5. TRAIN STACKED MODEL\n",
    "# --------------------------------------------------\n",
    "\n",
    "model = AdaBoostClassifier(n_estimators=150, learning_rate=0.7, random_state=42)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 6. EVALUATE\n",
    "# --------------------------------------------------\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 7. SAVE PREDICTIONS\n",
    "# --------------------------------------------------\n",
    "\n",
    "predictions = pd.DataFrame({\n",
    "    'date': features_df['date'].iloc[split:].reset_index(drop=True),\n",
    "    'actual': y_test,\n",
    "    'stacked_prediction': y_pred,\n",
    "    'stacked_probability': model.predict_proba(X_test_scaled)[:, 1]\n",
    "})\n",
    "\n",
    "# Add individual model predictions for comparison\n",
    "for model_name in ['lstm', 'gru', 'gbt']:\n",
    "    predictions[f'{model_name}_probability'] = features_df[f'{model_name}_prob'].iloc[split:].reset_index(drop=True)\n",
    "\n",
    "predictions.to_csv('model_predictions_stacked_adaboost.csv', index=False)\n",
    "print(\"\\nPredictions saved to: model_predictions_stacked_adaboost.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab2b736",
   "metadata": {},
   "source": [
    "IMplementing Random Forest now\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2db5d314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['date', 'actual_lstm', 'predicted_lstm', 'predicted_prob_lstm', 'prediction_date_lstm', 'model_version_lstm', 'actual_gru', 'predicted_gru', 'predicted_prob_gru', 'prediction_date_gru', 'model_version_gru', 'actual', 'predicted_prob_gbt', 'predicted', 's', 'o', 'h', 'l', 'c_x', 'v', 'psar_x', 'PosDI_x', 'NegDI_x', 'ADX_x', 'accumulated_sentiment_x', 'forecast_price', 'actual_label', 'predicted_label', 'c_y', 'psar_y', 'PosDI_y', 'NegDI_y', 'ADX_y', 'accumulated_sentiment_y']\n",
      "Accuracy: 0.6103\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.65      0.65        77\n",
      "           1       0.55      0.56      0.55        59\n",
      "\n",
      "    accuracy                           0.61       136\n",
      "   macro avg       0.60      0.60      0.60       136\n",
      "weighted avg       0.61      0.61      0.61       136\n",
      "\n",
      "\n",
      "Predictions saved to: model_predictions_stacked_rf.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 1. LOAD AND PREPARE DATA\n",
    "# --------------------------------------------------\n",
    "\n",
    "# Load data\n",
    "lstm_df = pd.read_csv('model_predictions-lstm-aws.csv')\n",
    "gru_df = pd.read_csv('model_predictions-gru-aws.csv')\n",
    "gbt_df = pd.read_csv('gbt_predictions15days.csv')\n",
    "arima_df = pd.read_csv('sarima_predictions.csv')\n",
    "feat_df = pd.read_csv('stock_with_sentiment-aggregated.csv')\n",
    "\n",
    "gru_df['date'] = pd.to_datetime(gru_df['date'])\n",
    "gbt_df['date'] = pd.to_datetime(gbt_df['date'])\n",
    "for df in [lstm_df, gru_df, gbt_df, arima_df, feat_df]:\n",
    "    df['date'] = df['date'].astype(str)\n",
    "\n",
    "# Select features from features dataframe\n",
    "feat_df = feat_df[['date', 'c', 'psar', 'PosDI', 'NegDI', 'ADX', 'accumulated_sentiment']]\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 2. MERGE ALL DATA\n",
    "# --------------------------------------------------\n",
    "\n",
    "# Merge all model predictions\n",
    "merged = pd.merge(lstm_df, gru_df, on='date', suffixes=('_lstm', '_gru'), how='inner')\n",
    "merged = pd.merge(merged, gbt_df, on='date', how='left')\n",
    "merged = pd.merge(merged, arima_df, on='date', how='left')\n",
    "merged = pd.merge(merged, feat_df, on='date', how='left')\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 3. CREATE FEATURES DATAFRAME\n",
    "# --------------------------------------------------\n",
    "\n",
    "features_df = pd.DataFrame()\n",
    "features_df['date'] = merged['date']\n",
    "\n",
    "# Target variable\n",
    "features_df['actual'] = merged['actual_lstm']\n",
    "\n",
    "# Model probabilities\n",
    "features_df['lstm_prob'] = merged['predicted_prob_lstm']\n",
    "features_df['gru_prob'] = merged['predicted_prob_gru']\n",
    "features_df['gbt_prob'] = merged['predicted_prob_gbt']\n",
    "merged.columns = merged.columns.str.strip()\n",
    "print(merged.columns.tolist())\n",
    "# ARIMA features\n",
    "features_df['arima_direction'] = merged['predicted_label'].astype(int)\n",
    "features_df['arima_return'] = (merged['forecast_price'] - merged['c_y']) / merged['c_y']\n",
    "\n",
    "# Technical indicators\n",
    "features_df['close_price'] = merged['c_y']\n",
    "features_df['psar'] = merged['psar_y']\n",
    "features_df['PosDI'] = merged['PosDI_y']\n",
    "features_df['NegDI'] = merged['NegDI_y']\n",
    "features_df['ADX'] = merged['ADX_y']\n",
    "features_df['accumulated_sentiment'] = merged['accumulated_sentiment_y']\n",
    "\n",
    "# Drop any rows with missing values\n",
    "features_df = features_df.dropna()\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 4. PREPARE FEATURES AND TARGET\n",
    "# --------------------------------------------------\n",
    "\n",
    "feature_cols = ['lstm_prob', 'gru_prob', 'gbt_prob', 'arima_direction', \n",
    "                'arima_return', 'close_price', 'psar', 'PosDI', 'NegDI', \n",
    "                'ADX', 'accumulated_sentiment']\n",
    "\n",
    "X = features_df[feature_cols].values\n",
    "y = features_df['actual'].values\n",
    "\n",
    "# Time-based split\n",
    "split = int(0.8 * len(X))\n",
    "X_train, X_test = X[:split], X[split:]\n",
    "y_train, y_test = y[:split], y[split:]\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 5. TRAIN STACKED MODEL (RANDOM FOREST)\n",
    "# --------------------------------------------------\n",
    "\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=200,      # Number of trees\n",
    "    max_depth=None,        # Let trees grow fully\n",
    "    min_samples_leaf=5,    # Minimum samples per leaf\n",
    "    random_state=42,\n",
    "    n_jobs=-1              # Use all cores\n",
    ")\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 6. EVALUATE\n",
    "# --------------------------------------------------\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 7. SAVE PREDICTIONS\n",
    "# --------------------------------------------------\n",
    "\n",
    "predictions = pd.DataFrame({\n",
    "    'date': features_df['date'].iloc[split:].reset_index(drop=True),\n",
    "    'actual': y_test,\n",
    "    'stacked_prediction': y_pred,\n",
    "    'stacked_probability': model.predict_proba(X_test_scaled)[:, 1]\n",
    "})\n",
    "\n",
    "# Add individual model predictions for comparison\n",
    "for model_name in ['lstm', 'gru', 'gbt']:\n",
    "    predictions[f'{model_name}_probability'] = features_df[f'{model_name}_prob'].iloc[split:].reset_index(drop=True)\n",
    "\n",
    "predictions.to_csv('model_predictions_stacked_rf.csv', index=False)\n",
    "print(\"\\nPredictions saved to: model_predictions_stacked_rf.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec47323",
   "metadata": {},
   "source": [
    "IMPLEMENTING GBT  model now\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43816896",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22c4e4dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['date', 'actual_lstm', 'predicted_lstm', 'predicted_prob_lstm', 'prediction_date_lstm', 'model_version_lstm', 'actual_gru', 'predicted_gru', 'predicted_prob_gru', 'prediction_date_gru', 'model_version_gru', 'actual', 'predicted_prob_gbt', 'predicted', 's', 'o', 'h', 'l', 'c_x', 'v', 'psar_x', 'PosDI_x', 'NegDI_x', 'ADX_x', 'accumulated_sentiment_x', 'forecast_price', 'actual_label', 'predicted_label', 'c_y', 'psar_y', 'PosDI_y', 'NegDI_y', 'ADX_y', 'accumulated_sentiment_y']\n",
      "Accuracy: 0.5441\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.53      0.57        77\n",
      "           1       0.48      0.56      0.52        59\n",
      "\n",
      "    accuracy                           0.54       136\n",
      "   macro avg       0.55      0.55      0.54       136\n",
      "weighted avg       0.55      0.54      0.55       136\n",
      "\n",
      "\n",
      "Predictions saved to: model_predictions_stacked_gbt.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 1. LOAD AND PREPARE DATA\n",
    "# --------------------------------------------------\n",
    "\n",
    "# Load data\n",
    "lstm_df = pd.read_csv('model_predictions-lstm-aws.csv')\n",
    "gru_df = pd.read_csv('model_predictions-gru-aws.csv')\n",
    "gbt_df = pd.read_csv('gbt_predictions15days.csv')\n",
    "arima_df = pd.read_csv('sarima_predictions.csv')\n",
    "feat_df = pd.read_csv('stock_with_sentiment-aggregated.csv')\n",
    "\n",
    "gru_df['date'] = pd.to_datetime(gru_df['date'])\n",
    "gbt_df['date'] = pd.to_datetime(gbt_df['date'])\n",
    "for df in [lstm_df, gru_df, gbt_df, arima_df, feat_df]:\n",
    "    df['date'] = df['date'].astype(str)\n",
    "\n",
    "# Select features from features dataframe\n",
    "feat_df = feat_df[['date', 'c', 'psar', 'PosDI', 'NegDI', 'ADX', 'accumulated_sentiment']]\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 2. MERGE ALL DATA\n",
    "# --------------------------------------------------\n",
    "\n",
    "merged = pd.merge(lstm_df, gru_df, on='date', suffixes=('_lstm', '_gru'), how='inner')\n",
    "merged = pd.merge(merged, gbt_df, on='date', how='left')\n",
    "merged = pd.merge(merged, arima_df, on='date', how='left')\n",
    "merged = pd.merge(merged, feat_df, on='date', how='left')\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 3. CREATE FEATURES DATAFRAME\n",
    "# --------------------------------------------------\n",
    "\n",
    "features_df = pd.DataFrame()\n",
    "features_df['date'] = merged['date']\n",
    "\n",
    "features_df['actual'] = merged['actual_lstm']\n",
    "\n",
    "features_df['lstm_prob'] = merged['predicted_prob_lstm']\n",
    "features_df['gru_prob'] = merged['predicted_prob_gru']\n",
    "features_df['gbt_prob'] = merged['predicted_prob_gbt']\n",
    "\n",
    "merged.columns = merged.columns.str.strip()\n",
    "print(merged.columns.tolist())\n",
    "\n",
    "features_df['arima_direction'] = merged['predicted_label'].astype(int)\n",
    "features_df['arima_return'] = (merged['forecast_price'] - merged['c_y']) / merged['c_y']\n",
    "\n",
    "features_df['close_price'] = merged['c_y']\n",
    "features_df['psar'] = merged['psar_y']\n",
    "features_df['PosDI'] = merged['PosDI_y']\n",
    "features_df['NegDI'] = merged['NegDI_y']\n",
    "features_df['ADX'] = merged['ADX_y']\n",
    "features_df['accumulated_sentiment'] = merged['accumulated_sentiment_y']\n",
    "\n",
    "features_df = features_df.dropna()\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 4. PREPARE FEATURES AND TARGET\n",
    "# --------------------------------------------------\n",
    "\n",
    "feature_cols = ['lstm_prob', 'gru_prob', 'gbt_prob', 'arima_direction', \n",
    "                'arima_return', 'close_price', 'psar', 'PosDI', 'NegDI', \n",
    "                'ADX', 'accumulated_sentiment']\n",
    "\n",
    "X = features_df[feature_cols].values\n",
    "y = features_df['actual'].values\n",
    "\n",
    "split = int(0.8 * len(X))\n",
    "X_train, X_test = X[:split], X[split:]\n",
    "y_train, y_test = y[:split], y[split:]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 5. TRAIN STACKED MODEL (GRADIENT BOOSTED TREES)\n",
    "# --------------------------------------------------\n",
    "\n",
    "model = GradientBoostingClassifier(\n",
    "    n_estimators=1000,       # number of boosting stages\n",
    "    learning_rate=0.05,     # shrinkage\n",
    "    max_depth=3,            # depth of each tree\n",
    "    subsample=0.8,          # fraction of samples for fitting each tree\n",
    "    min_samples_leaf=20,    # min samples per leaf\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 6. EVALUATE\n",
    "# --------------------------------------------------\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 7. SAVE PREDICTIONS\n",
    "# --------------------------------------------------\n",
    "\n",
    "predictions = pd.DataFrame({\n",
    "    'date': features_df['date'].iloc[split:].reset_index(drop=True),\n",
    "    'actual': y_test,\n",
    "    'stacked_prediction': y_pred,\n",
    "    'stacked_probability': model.predict_proba(X_test_scaled)[:, 1]\n",
    "})\n",
    "\n",
    "for model_name in ['lstm', 'gru', 'gbt']:\n",
    "    predictions[f'{model_name}_probability'] = features_df[f'{model_name}_prob'].iloc[split:].reset_index(drop=True)\n",
    "\n",
    "predictions.to_csv('model_predictions_stacked_gbt.csv', index=False)\n",
    "print(\"\\nPredictions saved to: model_predictions_stacked_gbt.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc1b4d4",
   "metadata": {},
   "source": [
    "IMPLEMENTING VOTING CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67246fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 1. LOAD MODEL OUTPUT FILES\n",
    "# --------------------------------------------------\n",
    "\n",
    "df1 = pd.read_csv('model_predictions-gru-aws.csv')\n",
    "df2 = pd.read_csv('model_predictions-lstm-aws.csv')\n",
    "df3 = pd.read_csv('model_predictions_gbt.csv')\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 2. MERGE ON DATE\n",
    "# --------------------------------------------------\n",
    "\n",
    "merged = df1[['date', 'actual', 'lstm_probability', 'gru_probability', 'gbt_probability']] \\\n",
    "    .merge(\n",
    "        df2[['date', 'lstm_probability', 'gru_probability', 'gbt_probability']],\n",
    "        on='date',\n",
    "        suffixes=('_1', '_2')\n",
    "    ) \\\n",
    "    .merge(\n",
    "        df3[['date', 'lstm_probability', 'gru_probability', 'gbt_probability']],\n",
    "        on='date'\n",
    "    )\n",
    "\n",
    "# Rename third file columns\n",
    "merged = merged.rename(columns={\n",
    "    'lstm_probability': 'lstm_probability_3',\n",
    "    'gru_probability': 'gru_probability_3',\n",
    "    'gbt_probability': 'gbt_probability_3'\n",
    "})\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 3. SOFT VOTING (PROBABILITY AVERAGING)\n",
    "# --------------------------------------------------\n",
    "\n",
    "merged['voted_probability'] = (\n",
    "    merged[\n",
    "        [\n",
    "            'lstm_probability_1', 'gru_probability_1', 'gbt_probability_1',\n",
    "            'lstm_probability_2', 'gru_probability_2', 'gbt_probability_2',\n",
    "            'lstm_probability_3', 'gru_probability_3', 'gbt_probability_3'\n",
    "        ]\n",
    "    ].mean(axis=1)\n",
    ")\n",
    "\n",
    "merged['voted_prediction'] = (merged['voted_probability'] >= 0.5).astype(int)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 4. EVALUATION\n",
    "# --------------------------------------------------\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(merged['actual'], merged['voted_prediction']))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(merged['actual'], merged['voted_prediction']))\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 5. SAVE RESULTS\n",
    "# --------------------------------------------------\n",
    "\n",
    "final_df = merged[['date', 'actual', 'voted_prediction', 'voted_probability']]\n",
    "final_df.to_csv('soft_voting_results.csv', index=False)\n",
    "\n",
    "print(\"\\nSoft voting results saved to soft_voting_results.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
